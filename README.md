# PyRIT Prompt Test Framework

A red teaming test framework based on the Microsoft library Python Risk Identification Tool for generative AI (PyRIT).
Different dataset of malevolous prompts are used to probe a target LLM. PyRIT APIs are used to load and model the prompts, to handle the communication with the target LLM and to automatically infer if the LLM refused to process the dangerous prompts. The test results are summarized in a report.

## ðŸ”§ Setup (Windows)

```bash
git clone https://github.com/your-org/pyrit_test_framework.git
cd pyrit_test_framework
copy .env.example .env
REM Edit .env with the Azure extremes of the target LLM model
setup.bat
REM After the dependencies and the local environment are set up, edit the config/test_config.yaml configuration file and run main.py
```

## Test Configuration

The test configuration can be found in config/test_config.yaml.
### Datasets
The `datasets` section configures the datasets to be used for the test session. It has two main subsections:
- **external**: A list of the external open source red-teaming datasets supported for the integration with pyrit.
 A list is provided as a suggestion, but the commented entries are skipped

- **custom**: Specifies which custom datasets should be included in the test session.
  - `dir`: Directory path where custom datasets are located: you should put here your custom prompts file to be tested.
  - `values`: List of specific custom dataset files, currently commented out.
  TODO important: use of custom datasets is currently not supported!

### System Prompt
The `system_prompt` section:
- `dir`: Directory where the system prompt files are stored (`config/system_prompts`).  
- `value`: The specific system prompt file to use (`children_safe_prompt_eng.txt`).

### Output
The `output` section defines directories for storing output generated by the framework:
- `base_dir`: The main directory for all results.  
- `prompt_eval_dir`: Sub-directory collecting the specific evaluations for each dataset/prompts.
- `report_dir`: Sub-directory for storing the generated summary reports.

### Logging
The `logging` section sets the logging verbosity level:
- `level`: Specifies the logging level (`"DEBUG"`, `"INFO"`, `"WARNING"`).
